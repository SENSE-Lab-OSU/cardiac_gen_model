{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cerebral Cortex Synthetic ECG Generation from the WESAD data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Run the following 2 cells ONLY if in Colab else skip them. They will install miniconda on Colab. Before running, first activate GPU by: Edit > Notebook settings > Hardware accelerator > GPU > Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pwd\n",
    "!which python\n",
    "!python --version\n",
    "#Check if GPU is detected\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "# If in Colab, install conda/mamba using condacolab python package and \n",
    "# wait until kernel restarts after the installation\n",
    "if IN_COLAB:\n",
    "    !pip install -q condacolab\n",
    "    import condacolab\n",
    "    condacolab.install_miniconda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Start running from following cell after kernel restarts OR when running locally on linux without dependencies installed. Don't run the cells above this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check notebook dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "HAVE_CARDIOGEN = importlib.util.find_spec(\"CardioGen\") is not None\n",
    "\n",
    "if(not HAVE_CARDIOGEN):\n",
    "    if IN_COLAB: \n",
    "        print(\"\\nGetting CardioGen\")\n",
    "        !git clone https://github.com/SENSE-Lab-OSU/cardio_gen_model.git\n",
    "        !conda env update -n base -f ./cardio_gen_model/conda_requirements_linux.yml\n",
    "        !pip install ./cardio_gen_model\n",
    "    else:\n",
    "        raise SystemExit(\"Please install CardioGen from https://github.com/SENSE-Lab-OSU/cardio_gen_model.git\")\n",
    "else:\n",
    "    print(\"CardioGen found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Start running from following cell when running locally on linux with all dependencies installed. Don't run the cells above this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import neurokit2 as nk\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the WESAD data if needed\n",
    "import shutil\n",
    "import getpass\n",
    "from zipfile import ZipFile\n",
    "import requests\n",
    "\n",
    "def download_file(url,local_path):\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        #r.raw.decode_content = True\n",
    "        with open(local_path, 'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    return local_path\n",
    "\n",
    "def unzip_file(zip_path,dir_path):\n",
    "    try:\n",
    "        with ZipFile(zip_path,'r') as zf:\n",
    "            zf.extractall(path=dir_path)\n",
    "    except RuntimeError:\n",
    "        print('AES Encrypted zip file. Need pyzipper to continue.\\n')\n",
    "        shutil.rmtree(dir_path, ignore_errors=True) #delete old dir\n",
    "        import pyzipper\n",
    "        with pyzipper.AESZipFile(zip_path,'r',encryption=pyzipper.WZ_AES) as zf:\n",
    "            pwd=getpass.getpass(prompt='Archive is password protected. Please enter the password to continue \\n')\n",
    "            zf.extractall(path=dir_path,pwd=pwd.encode())  \n",
    "\n",
    "def get_file(zip_file_url,zip_path,dir_path):\n",
    "    print('\\nDownloading {} File...\\n'.format(zip_path))\n",
    "    download_file(zip_file_url,zip_path)\n",
    "    print('Extracting Files from {}...\\n'.format(zip_path))\n",
    "    unzip_file(zip_path,dir_path)\n",
    "    print('Deleting temp Files...\\n')\n",
    "    os.remove(zip_path)\n",
    "    print('All Done!\\n')\n",
    "    return\n",
    "\n",
    "\n",
    "if IN_COLAB:\n",
    "    proj_path='./cardio_gen_model'\n",
    "else:\n",
    "    proj_path='.' \n",
    "\n",
    "data_dir=f'{proj_path}/data/pre-training'\n",
    "\n",
    "wesad_data_dir=data_dir+'/WESAD/'\n",
    "wesad_data_url='https://uni-siegen.sciebo.de/s/HGdUkoNlW1Ub0Gx/download'\n",
    "\n",
    "if (not os.path.exists(wesad_data_dir)):\n",
    "    get_file(wesad_data_url,data_dir+'/WESAD.zip',data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import useful library functions\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from math import gcd\n",
    "import neurokit2 as nk\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import time\n",
    "sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "import sys\n",
    "from CardioGen.lib.simulator_for_CC import Simulator\n",
    "from CardioGen.HR2Rpeaks import HR2Rpeaks_Simulator\n",
    "from CardioGen.Rpeaks2Sig import Rpeaks2Sig_Simulator\n",
    "from CardioGen.lib.utils import filtr_HR, get_continous_wins\n",
    "from CardioGen.lib.data import load_data_wesad as load_data\n",
    "\n",
    "#Define global constants\n",
    "model_path=proj_path+'/data/post-training/'\n",
    "data_path=proj_path+'/data/pre-training/WESAD/'\n",
    "\n",
    "n_classes=load_data.n_classes\n",
    "n_stresses=load_data.n_stresses\n",
    "all_class_ids=copy.deepcopy(load_data.class_ids)\n",
    "win_len_s=load_data.win_len_s\n",
    "step_s=load_data.step_s\n",
    "bsize=load_data.test_bsize\n",
    "Fs_ppg=load_data.Fs_ppg_new\n",
    "Fs_ecg=load_data.Fs_ecg_new\n",
    "\n",
    "ver=12 #version of the model_weights to use. Refer to README for details.\n",
    "Dsplit_filename = (f'{proj_path}/data/pre-training/'\n",
    "                   f'WESAD_musig_Dsplit_w{win_len_s}s{step_s}b{bsize}.pickle')\n",
    "if os.path.isfile(Dsplit_filename):\n",
    "    with open (Dsplit_filename, 'rb') as fp:\n",
    "        musig_dict,Dsplit_mask_dict = pickle.load(fp)\n",
    "else:\n",
    "    assert False, ('Could not find existing Dsplit_mask_dict. '\n",
    "                   'Run get_train_data in R2S mode first.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class avgHRV2PPG_Augmentor(Simulator):\n",
    "    '''\n",
    "    find peak_train. from there on, more or less ppg ecg\n",
    "    '''\n",
    "    def __init__(self,P_ID_out,path='../data/post-training/',\n",
    "                 latent_size_HRV=5,latent_size_Morph=2,Fs_tacho=5,\n",
    "                 Fs_out=None,win_len_s=8,step_s=2,bsize=13,\n",
    "                 dict_musig={}):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.Fs_tacho=Fs_tacho\n",
    "        self.Fs_out=Fs_out\n",
    "        self.P_ID_out=P_ID_out\n",
    "        self.path=path\n",
    "        self.latent_size_HRV=latent_size_HRV\n",
    "        self.latent_size_Morph=latent_size_Morph\n",
    "        self.win_len_s=win_len_s\n",
    "        self.step_s=step_s\n",
    "        self.bsize=bsize\n",
    "        self.dict_musig = dict_musig\n",
    "        up_factor=self.Fs_out/self.Fs_tacho\n",
    "        assert up_factor%1==0, 'Fs_out must be a multiple of Fs_tacho'\n",
    "        self.up_factor=int(up_factor)\n",
    "        #self.dict_musig=self.dict_musig[self.P_ID_out]\n",
    "        \n",
    "        P_ID_HRV='WESAD'\n",
    "        P_ID_Morph=P_ID_out\n",
    "\n",
    "        #Create a universal HR2Rpeaks_Simulator object \n",
    "        self.sim_HR2pks=HR2Rpeaks_Simulator(\n",
    "                    RNN_win_len_s=win_len_s+(bsize-1)*step_s,\n",
    "                    step_size_s=step_s,P_ID=P_ID_HRV,path=path,Fs_HR=Fs_tacho,\n",
    "                    Fs_tacho=Fs_tacho,latent_size=latent_size_HRV)\n",
    "        \n",
    "        #Create a subject-wise Rpeaks2Sig_Simulator object \n",
    "        self.sim_pks2ppg=Rpeaks2Sig_Simulator(Fs_in=Fs_out,Fs_out=Fs_out,\n",
    "                    P_ID=P_ID_Morph,path=path,sig_id='ppg',\n",
    "                    latent_size=latent_size_Morph,logging=False,batch_size=32,\n",
    "                    RNN_win_len=win_len_s,win_step_size=step_s)\n",
    "        \n",
    "    def __call__(self,cond_HRV):\n",
    "        \n",
    "        #Get synthetic R-peaks and tachogram from HR2Rpeaks_Simulator object\n",
    "        arr_pk_synth,cond_HRV,arr_tacho_synth=self.sim_HR2pks(cond_HRV,\n",
    "                    Fs_out=self.Fs_out,step_size_s=win_len_s+(bsize-1)*step_s)\n",
    "        \n",
    "        if len(arr_pk_synth)==0:\n",
    "            return None,None,None,None\n",
    "        cond_Morph=np.kron(cond_HRV[:,1:], np.ones((self.up_factor,1), \n",
    "                            dtype=cond_HRV[:,1:].dtype))\n",
    "        cond_ppg=np.concatenate([arr_pk_synth.reshape(-1,1),cond_Morph],axis=-1)\n",
    "        \n",
    "        #Get synthetic PPG from Rpeaks2Sig_Simulator object\n",
    "        ppg_synth,cond_ppg=self.sim_pks2ppg(cond_ppg,step_size_s=win_len_s)\n",
    "        \n",
    "        return cond_HRV,arr_tacho_synth,arr_pk_synth,ppg_synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all [avgHRV;Y_st;Y_Wid] windows and select train+val ones of SOI (ppg/ecg)\n",
    "def get_synth_data(avghrv2ppg_aug_dict,class_name,seq_format_function,\n",
    "                   Dsplit_mask_dict):\n",
    "    #class_name,Fs_out='S5',Fs_ppg\n",
    "    sample_key=list(avghrv2ppg_aug_dict.keys())[0]\n",
    "    Fs_out=avghrv2ppg_aug_dict[sample_key].Fs_out\n",
    "    Fs_tacho=avghrv2ppg_aug_dict[sample_key].Fs_tacho\n",
    "    \n",
    "    #for class_name in list(all_class_ids.keys()):\n",
    "    load_data.class_ids={class_name:all_class_ids[class_name]}\n",
    "    \n",
    "    #Load all data\n",
    "    list_cond_HRV,list_HRV,Dsplit_mask_dict=(load_data.get_train_data(\n",
    "                data_path,mode='HR2R',win_len_s=win_len_s,step_s=step_s,\n",
    "                Fs_tacho=Fs_tacho,Dsplit_mask_dict=Dsplit_mask_dict))\n",
    "    \n",
    "    #ppg_in_data,ppg_out_data=input_dict['ppg'][0],output_dict['ppg'][0]\n",
    "    \n",
    "    Dsplit_mask=Dsplit_mask_dict['hrv'][class_name] #must use hrv mask\n",
    "    train_mask=Dsplit_mask[0].astype(int)\n",
    "    #val_train_mask= np.sum(Dsplit_mask[0:2],axis=0).astype(int)\n",
    "    sel_mask=train_mask*1\n",
    "    \n",
    "    start_idxs,end_idxs=get_continous_wins(sel_mask)\n",
    "    #start_idxs,n_stresses,n_classes=start_idxs[:2],3,2#TODO:For Debugging only\n",
    "    print(f'Generating synthetic data using subject {class_name} with '\n",
    "          f'{len(start_idxs)} sequences')\n",
    "    \n",
    "    in_data_synth=[[] for j in range((n_stresses-1)*n_classes)]\n",
    "    out_data_synth=[[] for j in range((n_stresses-1)*n_classes)]\n",
    "\n",
    "    # Iterate over each set and generate data\n",
    "    for i in range(len(start_idxs)):\n",
    "    #for i in range(2):\n",
    "        \n",
    "        # Defragment windows into continous signal segments.\n",
    "        in_seq_wins=list_cond_HRV[0][start_idxs[i]:end_idxs[i]]\n",
    "        in_seq=(load_data.sliding_window_defragmentation([in_seq_wins],\n",
    "                    ((bsize-1)*step_s+win_len_s)*Fs_tacho,\n",
    "                    step_s*Fs_tacho))\n",
    "        \n",
    "        \n",
    "        # Pick a signal and divide [avgHRV],[Y_st],[Y_Wid]. Keeping avgHRV fixed and \n",
    "        # cycle through 4 (out of 5) stress conditions and all 15 classes. So for \n",
    "        # every signal, we get 15*4=60 signals + 1 original signal. Hence, net \n",
    "        # augmentation factor of 61.\n",
    "        cond_HRV_init=np.zeros(in_seq.shape)\n",
    "        cond_HRV_init[:,0]=in_seq[:,0]*1\n",
    "        start_time=time.time()\n",
    "        #avghrv2ppg_aug=avghrv2ppg_aug_dict[sample_key]\n",
    "        \n",
    "        for s in [0,3]:\n",
    "        #for s in range(n_stresses-1):\n",
    "            for c in range(n_classes)[:]:\n",
    "                print(f'Stress={s+1}, Class={c}')\n",
    "                j=s*n_classes+c #counter\n",
    "                cond_HRV=cond_HRV_init*1\n",
    "                cond_HRV[:,1+s+1]=1 #extra +1 for skipping stress=0 channel\n",
    "                cond_HRV[:,1+n_stresses+c]=1\n",
    "                \n",
    "                #Pick subject-specific model\n",
    "                avghrv2ppg_aug=avghrv2ppg_aug_dict[list(all_class_ids.keys())\n",
    "                                                    [c]]\n",
    "                #Generate Synthetic data\n",
    "                cond_HRV,arr_tacho_synth,arr_pk_synth,ppg_synth=avghrv2ppg_aug(\n",
    "                                                                cond_HRV)\n",
    "                ppg_synth*=musig_dict[list(all_class_ids.keys())[c]]['ppg']['sigma'] #rescale\n",
    "                ppg_synth+=musig_dict[list(all_class_ids.keys())[c]]['ppg']['mu'] #add back mean\n",
    "                \n",
    "                if cond_HRV is None:\n",
    "                    #in_wins,out_wins=None,None\n",
    "                    continue\n",
    "                else:\n",
    "                    in_wins,out_wins=seq_format_function(avghrv2ppg_aug,cond_HRV,\n",
    "                                    arr_tacho_synth,arr_pk_synth,ppg_synth)\n",
    "                    in_data_synth[j].append(in_wins)\n",
    "                    out_data_synth[j].append(out_wins)\n",
    "                    \n",
    "        print(f'Time taken for sequence {i}= {time.time()-start_time}')\n",
    "    in_data_list=[np.concatenate(arr_list,axis=0) \n",
    "                  for arr_list in in_data_synth if len(arr_list)>0]\n",
    "    out_data_list=[np.concatenate(arr_list,axis=0) \n",
    "                   for arr_list in out_data_synth if len(arr_list)>0]\n",
    "    print('\\n=======================\\n',len(out_data_list))\n",
    "    in_data=np.concatenate(in_data_list,axis=0).astype(np.float32)\n",
    "    out_data=np.concatenate(out_data_list,axis=0).astype(np.float32)\n",
    "    \n",
    "    # samp_idx=10\n",
    "    # plt.figure();plt.plot(in_data[samp_idx,:,:])\n",
    "    # plt.plot(out_data[samp_idx,:,:])\n",
    "    return in_data,out_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_format_function_TAu(avghrv2ppg_aug,cond_HRV,arr_tacho_synth,\n",
    "                            arr_pk_synth,ppg_synth):\n",
    "    bsize,bstep=5,2#1 #TODO: we can increase bstep here\n",
    "    Fs_out=avghrv2ppg_aug.Fs_out\n",
    "    seq_in=ppg_synth\n",
    "    #seq_out=cond_HRV[:,0].reshape(-1,1)\n",
    "    seq_out=np.stack([cond_HRV[:,0],arr_tacho_synth],axis=1)\n",
    "    \n",
    "    #upsample seq_out to Fs_out\n",
    "    #up_factor=avghrv2ppg_aug.Fs_out/avghrv2ppg_aug.Fs_tacho\n",
    "    #assert up_factor%1==0, f'up_factor should have been an integer. but is {up_factor}'\n",
    "    \n",
    "    seq_out=load_data.resample(seq_out,avghrv2ppg_aug.Fs_tacho,\n",
    "                avghrv2ppg_aug.up_factor,1,show_plots=False)\n",
    "    #print(seq_out.shape)\n",
    "    # Apt block creation as per TAu but using Dsplit_mask['hrv']\n",
    "    # Fragment all signals back to desired fragmentation. Could reuse train & val\n",
    "    # masks for Dsplit (although potential issue with GRU memory propagation is \n",
    "    # val data may now have seen more train data in a sense)\n",
    "    in_wins,out_wins=load_data.sliding_window_fragmentation([seq_in,seq_out],\n",
    "                    ((bsize-1)*step_s+win_len_s)*Fs_out,\n",
    "                    bstep*step_s*Fs_out)\n",
    "    return in_wins,out_wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_format_function=seq_format_function_TAu\n",
    "save_name='WESAD_synth_TAu/ppg'\n",
    "show_plots=False\n",
    "suffix='s14_c'\n",
    "\n",
    "#P_ID='WESAD'\n",
    "latent_size_HRV=4\n",
    "latent_size_Morph=2\n",
    "Fs_tacho=5\n",
    "\n",
    "\n",
    "    \n",
    "#Load all augmentor models in a single dict\n",
    "avghrv2ppg_aug_dict={}\n",
    "\n",
    "def get_aug_dict():\n",
    "    for clas_name in list(all_class_ids.keys())[:]:\n",
    "        #Create Simulator Model\n",
    "        avghrv2ppg_aug=avgHRV2PPG_Augmentor(P_ID_out=clas_name,path=model_path,\n",
    "                        latent_size_HRV=latent_size_HRV,\n",
    "                        latent_size_Morph=latent_size_Morph,Fs_tacho=Fs_tacho,\n",
    "                        Fs_out=Fs_ppg,win_len_s=win_len_s,\n",
    "                        step_s=step_s,bsize=bsize)\n",
    "        \n",
    "        # Put specialized models in a dict\n",
    "        #avghrv2ppg_aug_list.append(avghrv2ppg_aug)\n",
    "        avghrv2ppg_aug_dict[clas_name]=avghrv2ppg_aug\n",
    "        del avghrv2ppg_aug\n",
    "    print(len(avghrv2ppg_aug_dict))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HRV Gen Model Exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/WESAD_HRV_model\\ckpt-2000\n",
      "Done!\n",
      "ppg Morph gen_model exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/S2_ppg_Morph_model\\ckpt-2400\n",
      "Done!\n",
      "HRV Gen Model Exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/WESAD_HRV_model\\ckpt-2000\n",
      "Done!\n",
      "ppg Morph gen_model exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/S3_ppg_Morph_model\\ckpt-2400\n",
      "Done!\n",
      "HRV Gen Model Exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/WESAD_HRV_model\\ckpt-2000\n",
      "Done!\n",
      "ppg Morph gen_model exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/S4_ppg_Morph_model\\ckpt-2400\n",
      "Done!\n",
      "HRV Gen Model Exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/WESAD_HRV_model\\ckpt-2000\n",
      "Done!\n",
      "ppg Morph gen_model exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/S5_ppg_Morph_model\\ckpt-2400\n",
      "Done!\n",
      "HRV Gen Model Exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/WESAD_HRV_model\\ckpt-2000\n",
      "Done!\n",
      "ppg Morph gen_model exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/S6_ppg_Morph_model\\ckpt-2400\n",
      "Done!\n",
      "HRV Gen Model Exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/WESAD_HRV_model\\ckpt-2000\n",
      "Done!\n",
      "ppg Morph gen_model exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/S7_ppg_Morph_model\\ckpt-2400\n",
      "Done!\n",
      "HRV Gen Model Exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/WESAD_HRV_model\\ckpt-2000\n",
      "Done!\n",
      "ppg Morph gen_model exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/S8_ppg_Morph_model\\ckpt-2400\n",
      "Done!\n",
      "HRV Gen Model Exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/WESAD_HRV_model\\ckpt-2000\n",
      "Done!\n",
      "ppg Morph gen_model exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/S9_ppg_Morph_model\\ckpt-2400\n",
      "Done!\n",
      "HRV Gen Model Exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/WESAD_HRV_model\\ckpt-2000\n",
      "Done!\n",
      "ppg Morph gen_model exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/S10_ppg_Morph_model\\ckpt-2400\n",
      "Done!\n",
      "HRV Gen Model Exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/WESAD_HRV_model\\ckpt-2000\n",
      "Done!\n",
      "ppg Morph gen_model exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/S11_ppg_Morph_model\\ckpt-2400\n",
      "Done!\n",
      "HRV Gen Model Exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/WESAD_HRV_model\\ckpt-2000\n",
      "Done!\n",
      "ppg Morph gen_model exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/S13_ppg_Morph_model\\ckpt-2400\n",
      "Done!\n",
      "HRV Gen Model Exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/WESAD_HRV_model\\ckpt-2000\n",
      "Done!\n",
      "ppg Morph gen_model exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/S14_ppg_Morph_model\\ckpt-2400\n",
      "Done!\n",
      "HRV Gen Model Exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/WESAD_HRV_model\\ckpt-2000\n",
      "Done!\n",
      "ppg Morph gen_model exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/S15_ppg_Morph_model\\ckpt-2400\n",
      "Done!\n",
      "HRV Gen Model Exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/WESAD_HRV_model\\ckpt-2000\n",
      "Done!\n",
      "ppg Morph gen_model exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/S16_ppg_Morph_model\\ckpt-2400\n",
      "Done!\n",
      "HRV Gen Model Exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/WESAD_HRV_model\\ckpt-2000\n",
      "Done!\n",
      "ppg Morph gen_model exists. Loading ...\n",
      "Restored from ./data/post-training/model_weights_v12/S17_ppg_Morph_model\\ckpt-2400\n",
      "Done!\n",
      "15\n",
      "S2 \n",
      "\n",
      "Generating synthetic data using subject S2 with 42 sequences\n",
      "Stress=1, Class=0\n",
      "Stress=1, Class=1\n",
      "Stress=1, Class=2\n",
      "Stress=1, Class=3\n",
      "Stress=1, Class=4\n",
      "Stress=1, Class=5\n",
      "Stress=1, Class=6\n",
      "Stress=1, Class=7\n",
      "Stress=1, Class=8\n",
      "Stress=1, Class=9\n",
      "Stress=1, Class=10\n",
      "Stress=1, Class=11\n",
      "Stress=1, Class=12\n",
      "Stress=1, Class=13\n",
      "Stress=1, Class=14\n",
      "Stress=4, Class=0\n",
      "Stress=4, Class=1\n",
      "Stress=4, Class=2\n",
      "Stress=4, Class=3\n",
      "Stress=4, Class=4\n",
      "Stress=4, Class=5\n",
      "Stress=4, Class=6\n",
      "Stress=4, Class=7\n",
      "Stress=4, Class=8\n",
      "Stress=4, Class=9\n",
      "Stress=4, Class=10\n",
      "Stress=4, Class=11\n",
      "Stress=4, Class=12\n",
      "Stress=4, Class=13\n",
      "Stress=4, Class=14\n",
      "Time taken for sequence 0= 50.487510681152344\n",
      "Stress=1, Class=0\n",
      "Stress=1, Class=1\n",
      "Stress=1, Class=2\n",
      "Stress=1, Class=3\n",
      "Stress=1, Class=4\n",
      "Stress=1, Class=5\n",
      "Stress=1, Class=6\n",
      "Stress=1, Class=7\n",
      "Stress=1, Class=8\n",
      "Stress=1, Class=9\n",
      "Stress=1, Class=10\n",
      "Stress=1, Class=11\n",
      "Stress=1, Class=12\n",
      "Stress=1, Class=13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\TEMPCO~1.005\\AppData\\Local\\Temp/ipykernel_6216/1142992741.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavghrv2ppg_aug_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mget_aug_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         in_data,out_data=get_synth_data(avghrv2ppg_aug_dict,class_name,\n\u001b[1;32m---> 16\u001b[1;33m                                     seq_format_function,Dsplit_mask_dict)\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;31m# Save data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\TEMPCO~1.005\\AppData\\Local\\Temp/ipykernel_6216/3941240238.py\u001b[0m in \u001b[0;36mget_synth_data\u001b[1;34m(avghrv2ppg_aug_dict, class_name, seq_format_function, Dsplit_mask_dict)\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[1;31m#Generate Synthetic data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                 cond_HRV,arr_tacho_synth,arr_pk_synth,ppg_synth=avghrv2ppg_aug(\n\u001b[1;32m---> 66\u001b[1;33m                                                                 cond_HRV)\n\u001b[0m\u001b[0;32m     67\u001b[0m                 \u001b[0mppg_synth\u001b[0m\u001b[1;33m*=\u001b[0m\u001b[0mmusig_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_class_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ppg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sigma'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#rescale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mppg_synth\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mmusig_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_class_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ppg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mu'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#add back mean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\TEMPCO~1.005\\AppData\\Local\\Temp/ipykernel_6216/3851777792.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, cond_HRV)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;31m#Get synthetic PPG from Rpeaks2Sig_Simulator object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mppg_synth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcond_ppg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msim_pks2ppg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond_ppg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstep_size_s\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwin_len_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcond_HRV\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0marr_tacho_synth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0marr_pk_synth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mppg_synth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\agarwal270\\Research\\Projects\\cardio_gen_model\\CardioGen\\Rpeaks2Sig.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, cond_sig, step_size_s, show_plots)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond_sig_windows\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             arr[i:i+1]=self.gen_model.predict([cond_sig_windows[i:i+1]],\n\u001b[1;32m--> 327\u001b[1;33m                             rnn_state=rnn_state,rnn_state_out_no=step_size-1)\n\u001b[0m\u001b[0;32m    328\u001b[0m             \u001b[0mrnn_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn_state_out\u001b[0m \u001b[1;31m#update state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\agarwal270\\Research\\Projects\\cardio_gen_model\\CardioGen\\lib\\model_CondWGAN.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, test_data, rnn_state, rnn_state_out_no)\u001b[0m\n\u001b[0;32m    742\u001b[0m                             test_data[0][i:i+batch_size_test]] #Dummy y to test_step\n\u001b[0;32m    743\u001b[0m                             \u001b[1;33m,\u001b[0m\u001b[0min_prediction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrnn_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrnn_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m                             rnn_state_out_no=rnn_state_out_no)\n\u001b[0m\u001b[0;32m    745\u001b[0m             \u001b[0mtest_y_hat_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\agarwal270\\Research\\Projects\\cardio_gen_model\\CardioGen\\lib\\model_CondWGAN.py\u001b[0m in \u001b[0;36mtest_step\u001b[1;34m(self, data, in_prediction, rnn_state, rnn_state_out_no)\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[0mz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_z_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m         y_hat = self.gen([z,x], training=False, rnn_state=rnn_state,\n\u001b[1;32m--> 569\u001b[1;33m                          rnn_state_out_no=rnn_state_out_no)\n\u001b[0m\u001b[0;32m    570\u001b[0m         \u001b[1;32mif\u001b[0m  \u001b[0min_prediction\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0my_hat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf_gpu_5\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    821\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 822\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\agarwal270\\Research\\Projects\\cardio_gen_model\\CardioGen\\lib\\model_CondWGAN.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input_list, training, rnn_state, rnn_state_out_no)\u001b[0m\n\u001b[0;32m    231\u001b[0m             Unet_out,rnn_state=self.Unet([inputs[:,i,:,:,:],rnn_state],\n\u001b[0;32m    232\u001b[0m                         \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrnn_state_out_no\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrnn_state_out_no\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m                         update_rnn_state_out=(i==update_rnn_idx))\n\u001b[0m\u001b[0;32m    234\u001b[0m             \u001b[0mout_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mUnet_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[1;31m#dec_mem = z[:,-mem_shape[0]:]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\agarwal270\\Research\\Projects\\cardio_gen_model\\CardioGen\\lib\\model_CondWGAN.py\u001b[0m in \u001b[0;36mUnet\u001b[1;34m(self, input_list, training, rnn_state_out_no, update_rnn_state_out)\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[1;31m#if i!=0: x=tf.concat([x,skips[i]],axis=-1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#last unet layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#remove the dummy dim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf_gpu_5\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    821\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 822\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\agarwal270\\Research\\Projects\\cardio_gen_model\\CardioGen\\lib\\networks_GAN.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, x, training)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlay\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[1;31m#print(x.shape.as_list())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf_gpu_5\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    821\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 822\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf_gpu_5\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    851\u001b[0m       \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 853\u001b[1;33m     \u001b[0moutput_shape_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    854\u001b[0m     outputs = backend.conv2d_transpose(\n\u001b[0;32m    855\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf_gpu_5\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf_gpu_5\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1242\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m       \u001b[1;31m# If the input is a constant list, it can be converted to a constant op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1244\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1245\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m       \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Input list contains non-constant tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf_gpu_5\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf_gpu_5\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m   1366\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_cast_nested_seqs_to_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_autopacking_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"packed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf_gpu_5\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_autopacking_helper\u001b[1;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[0;32m   1302\u001b[0m           elems_as_tensors.append(\n\u001b[0;32m   1303\u001b[0m               constant_op.constant(elem, dtype=dtype, name=str(i)))\n\u001b[1;32m-> 1304\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melems_as_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1305\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_elems\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf_gpu_5\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mpack\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   5682\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m   5683\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Pack\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5684\u001b[1;33m         values, \"axis\", axis)\n\u001b[0m\u001b[0;32m   5685\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5686\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_dir=f'{model_path}/{save_name}'\n",
    "os.makedirs(save_dir,exist_ok=True)\n",
    "in_data_list,out_data_list=[],[]\n",
    "#class_name='S7'\n",
    "#for class_name in ['S15']:#,'S11','S17']:\n",
    "\n",
    "for class_name in list(all_class_ids.keys())[:]:\n",
    "    filename = (save_dir+f'/{class_name}_{suffix}.pickle')\n",
    "    \n",
    "    if os.path.isfile(filename):\n",
    "        with open (filename, 'rb') as fp:\n",
    "            in_data,out_data = pickle.load(fp)\n",
    "    else:\n",
    "        if len(avghrv2ppg_aug_dict)==0: get_aug_dict()\n",
    "        in_data,out_data=get_synth_data(avghrv2ppg_aug_dict,class_name,\n",
    "                                    seq_format_function,Dsplit_mask_dict)\n",
    "        # Save data\n",
    "        with open(filename, 'wb') as handle:\n",
    "            pickle.dump([in_data,out_data], handle)\n",
    "            \n",
    "    print(in_data.shape,out_data.shape)\n",
    "    in_data_list.append(in_data)\n",
    "    out_data_list.append(out_data)    \n",
    "    \n",
    "in_data=np.concatenate(in_data_list,axis=0).astype(np.float32)\n",
    "out_data=np.concatenate(out_data_list,axis=0).astype(np.float32)\n",
    "print(in_data.shape,out_data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
